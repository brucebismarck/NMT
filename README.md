# NMT
Neural Machine Translation with attention in both encoder and decoder


This is a project from Dr. Mohit NLP class's final project. The detail description was shown in the tex pdf.

Feature:
1. Seq2Seq with 3layers biGRU  model as encoder and decoder
2. global attention in decoder
3. self attention in encoder
4. Alignment and visualization
5. Model Evaluation.
